{"cells":[{"cell_type":"markdown","metadata":{"id":"Pcuk5Ze3jG9D"},"source":["A cute little demo showing the simplest usage of minGPT. Configured to run fine on Macbook Air in like a minute."]},{"cell_type":"code","source":["!git clone https://github.com/karpathy/minGPT.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugE-P-9jjWJ1","executionInfo":{"status":"ok","timestamp":1737206268389,"user_tz":-60,"elapsed":6275,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}},"outputId":"84aebc60-a25d-45b0-ab44-a89b33764b4b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'minGPT'...\n","remote: Enumerating objects: 489, done.\u001b[K\n","remote: Counting objects: 100% (239/239), done.\u001b[K\n","remote: Compressing objects: 100% (94/94), done.\u001b[K\n","remote: Total 489 (delta 153), reused 145 (delta 145), pack-reused 250 (from 1)\u001b[K\n","Receiving objects: 100% (489/489), 1.43 MiB | 9.35 MiB/s, done.\n","Resolving deltas: 100% (267/267), done.\n","Obtaining file:///content\n","\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!cd minGPT\n","!pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZYWGc7CkLYC","executionInfo":{"status":"ok","timestamp":1737206318394,"user_tz":-60,"elapsed":1536,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}},"outputId":"f643c895-a97d-4e57-9ccd-5e7c0c250b1a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content\n","\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from .mingpt.utils import set_seed"],"metadata":{"id":"7D-ZkjZvkhke","executionInfo":{"status":"error","timestamp":1737206413979,"user_tz":-60,"elapsed":5,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}},"outputId":"82cb6230-0ab0-4955-bbcf-f8e256e65a4b","colab":{"base_uri":"https://localhost:8080/","height":314}},"execution_count":5,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"attempted relative import with no known parent package","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3e24048eef42>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmingpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"rCCtKgP5jG9I","executionInfo":{"status":"error","timestamp":1737206273743,"user_tz":-60,"elapsed":5357,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}},"outputId":"16446a71-7e14-4468-ff81-2709b5eea787"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'mingpt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c0443eea062d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmingpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3407\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mingpt'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","from mingpt.utils import set_seed\n","set_seed(3407)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fEvPANUjG9K","executionInfo":{"status":"aborted","timestamp":1737206273744,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["import pickle\n","\n","class SortDataset(Dataset):\n","    \"\"\"\n","    Dataset for the Sort problem. E.g. for problem length 6:\n","    Input: 0 0 2 1 0 1 -> Output: 0 0 0 1 1 2\n","    Which will feed into the transformer concatenated as:\n","    input:  0 0 2 1 0 1 0 0 0 1 1\n","    output: I I I I I 0 0 0 1 1 2\n","    where I is \"ignore\", as the transformer is reading the input sequence\n","    \"\"\"\n","\n","    def __init__(self, split, length=6, num_digits=3):\n","        assert split in {'train', 'test'}\n","        self.split = split\n","        self.length = length\n","        self.num_digits = num_digits\n","\n","    def __len__(self):\n","        return 10000 # ...\n","\n","    def get_vocab_size(self):\n","        return self.num_digits\n","\n","    def get_block_size(self):\n","        # the length of the sequence that will feed into transformer,\n","        # containing concatenated input and the output, but -1 because\n","        # the transformer starts making predictions at the last input element\n","        return self.length * 2 - 1\n","\n","    def __getitem__(self, idx):\n","\n","        # use rejection sampling to generate an input example from the desired split\n","        while True:\n","            # generate some random integers\n","            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n","            # half of the time let's try to boost the number of examples that\n","            # have a large number of repeats, as this is what the model seems to struggle\n","            # with later in training, and they are kind of rate\n","            if torch.rand(1).item() < 0.5:\n","                if inp.unique().nelement() > self.length // 2:\n","                    # too many unqiue digits, re-sample\n","                    continue\n","            # figure out if this generated example is train or test based on its hash\n","            h = hash(pickle.dumps(inp.tolist()))\n","            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n","            if inp_split == self.split:\n","                break # ok\n","\n","        # solve the task: i.e. sort\n","        sol = torch.sort(inp)[0]\n","\n","        # concatenate the problem specification and the solution\n","        cat = torch.cat((inp, sol), dim=0)\n","\n","        # the inputs to the transformer will be the offset sequence\n","        x = cat[:-1].clone()\n","        y = cat[1:].clone()\n","        # we only want to predict at output locations, mask out the loss at the input locations\n","        y[:self.length-1] = -1\n","        return x, y\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wrK89zPjG9K","executionInfo":{"status":"aborted","timestamp":1737206273744,"user_tz":-60,"elapsed":6,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIz0BjqajG9L","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["import random\n","\n","def random_add_instance(length):\n","    a = [random.randint(0,9) for i in range(length)]\n","    b = [random.randint(0,9) for i in range(length)]\n","    val_a = int(''.join(str(d) for d in a))\n","    val_b = int(''.join(str(d) for d in b))\n","    val_c = val_a + val_b\n","    str_c = str(val_c)\n","    str_c = (length + 1 - len(str_c)) * '0' + str_c\n","    return a + b + [int(d) for d in str_c]\n","\n","for i in range(10):\n","    print (random_add_instance(3))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8zZ6DbAjG9M","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["class AddDataset(Dataset):\n","    \"\"\"\n","    Dataset for the Add problem. E.g. for problem length 3:\n","    12 + 333 = 345\n","    Input: 0 1 2 3 3 3 -> Output: 0 3 4 5\n","    Which will feed into the transformer concatenated as:\n","    input:  0 1 2 3 3 3 0 3 4\n","    output: I I I I I 0 3 4 5\n","    where I is \"ignore\", as the transformer is reading the input sequence\n","    \"\"\"\n","\n","    def __init__(self, split, length=3):\n","        assert split in {'train', 'test'}\n","        self.split = split\n","        self.length = length\n","\n","    def __len__(self):\n","        return 10000 # ...\n","\n","    def get_vocab_size(self):\n","        return 10\n","\n","    def get_block_size(self):\n","        # the length of the sequence that will feed into transformer,\n","        # containing concatenated input and the output, but -1 because\n","        # the transformer starts making predictions at the last input element\n","        return 3 * self.length + 1 - 1\n","\n","    def __getitem__(self, idx):\n","        while True:\n","            rai = random_add_instance(self.length)\n","            h = hash(str(rai[:2*self.length]))\n","\n","            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n","            if inp_split == self.split:\n","                break # ok\n","\n","        x = torch.tensor(rai[:-1], dtype=torch.long)\n","        y = torch.tensor(rai[1:], dtype=torch.long)\n","\n","        # we only want to predict at output locations, mask out the loss at the input locations\n","        y[:2*self.length-1] = -1\n","        return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSYsamx0jG9M","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["# print an example instance of the dataset\n","train_dataset = AddDataset('train')\n","test_dataset = AddDataset('test')\n","x, y = train_dataset[0]\n","\n","print (x)\n","for a, b in zip(x,y):\n","    print(int(a),int(b))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_VksjnAOjG9N","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-o9fwY7jG9N","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["# create a GPT instance\n","from mingpt.model import GPT\n","\n","model_config = GPT.get_default_config()\n","model_config.model_type = 'gpt-micro'\n","model_config.model_type = 'gpt-nano'\n","\n","model_config.vocab_size = train_dataset.get_vocab_size()\n","model_config.block_size = train_dataset.get_block_size()\n","model = GPT(model_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1GD0wK0jG9N","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["print (model_config.n_head, model_config.n_layer, model_config.n_embd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2l8EGvukjG9O","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":6,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["# create a Trainer object\n","from mingpt.trainer import Trainer\n","\n","train_config = Trainer.get_default_config()\n","train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n","train_config.max_iters = 5000\n","train_config.num_workers = 0\n","trainer = Trainer(train_config, model, train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QK4EZqpBjG9O","executionInfo":{"status":"aborted","timestamp":1737206273745,"user_tz":-60,"elapsed":6,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["def batch_end_callback(trainer):\n","    if trainer.iter_num % 100 == 0:\n","        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n","trainer.set_callback('on_batch_end', batch_end_callback)\n","\n","trainer.run()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJdEIdwQjG9O","executionInfo":{"status":"aborted","timestamp":1737206273746,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["# now let's perform some evaluation\n","model.eval()\n","None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N51TV1DujG9P","executionInfo":{"status":"aborted","timestamp":1737206273746,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":["def eval_add_split(trainer, split, max_batches):\n","    dataset = {'train':train_dataset, 'test':test_dataset}[split]\n","    n = train_dataset.length # naugy direct access shrug\n","    results = []\n","    mistakes_printed_already = 0\n","    loader = DataLoader(dataset, batch_size=100, num_workers=0, drop_last=False)\n","    #loader = DataLoader(dataset, batch_size=1, num_workers=0, drop_last=False)\n","    for b, (x, y) in enumerate(loader):\n","        x = x.to(trainer.device)\n","        y = y.to(trainer.device)\n","\n","        inp = x[:, :2*n]\n","        sol = y[:, -n-1:]\n","\n","        cat = model.generate(inp, n+1, do_sample=False) # using greedy argmax, not sampling\n","        sol_candidate = cat[:, -n-1:]\n","        correct = (sol == sol_candidate).all(1).cpu()\n","        for i in range(x.size(0)):\n","            results.append(int(correct[i]))\n","\n","    rt = torch.tensor(results, dtype=torch.float)\n","    print(\"%s final score: %d/%d = %.2f%% correct\" % (split, rt.sum(), len(results), 100*rt.mean()))\n","    return rt.sum()\n","\n","# run a lot of examples from both train and test through the model and verify the output correctness\n","with torch.no_grad():\n","    train_score = eval_add_split(trainer, 'train', max_batches=50)\n","    test_score  = eval_add_split(trainer, 'test',  max_batches=50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mxf57SLJjG9P","executionInfo":{"status":"aborted","timestamp":1737206273746,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrY8qGkvjG9P","executionInfo":{"status":"aborted","timestamp":1737206273746,"user_tz":-60,"elapsed":7,"user":{"displayName":"Wojtek Śniady","userId":"02790611880902797330"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"}},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}